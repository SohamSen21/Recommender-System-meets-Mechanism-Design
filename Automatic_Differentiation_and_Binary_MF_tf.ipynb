{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMx5xSBn26akgg9Hg+cyX1y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SohamSen21/Recommender-System-meets-Mechanism-Design/blob/main/Automatic_Differentiation_and_Binary_MF_tf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def mf(R, k, n_epoch=5000, lr=.0003, l2=.04):\n",
        "  tol = .001  # Tolerant loss.\n",
        "  m, n = R.shape\n",
        "  # Initialize the embedding weights.\n",
        "  P = np.random.rand(m, k)\n",
        "  Q = np.random.rand(n, k)\n",
        "  for epoch in range(n_epoch):\n",
        "    # Update weights by gradients.\n",
        "    for u, i in zip(*R.nonzero()):\n",
        "      err_ui = R[u,i] - P[u,:].dot(Q[i,:])\n",
        "      for j in range(k):\n",
        "        P[u][j] += lr * (2 * err_ui * Q[i][j] - l2/2 * P[u][j])\n",
        "        Q[i][j] += lr * (2 * err_ui * P[u][j] - l2/2 * Q[i][j])\n",
        "    # compute the loss.\n",
        "    E = (R - P.dot(Q.T))**2\n",
        "    obj = E[R.nonzero()].sum() + lr*((P**2).sum() +(Q**2).sum())\n",
        "    if obj < tol:\n",
        "        break\n",
        "  return P, Q\n"
      ],
      "metadata": {
        "id": "n07ERNhvRMJp"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(777)\n",
        "\n",
        "# Make missing more prevail.\n",
        "stars = np.arange(6)\n",
        "p = np.array([10, 1, 1, 1, 1, 1])\n",
        "m = 5\n",
        "n = 10\n",
        "\n",
        "# A 5-star rating matrix.\n",
        "ratings = np.random.choice(stars, size=m*n, p=p / p.sum()).reshape((m, n))\n",
        "print(ratings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YoyDI07RSdSj",
        "outputId": "9727c40b-642b-417b-9c0a-333fe717783e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0 0 0 3 4 1 2 0 0]\n",
            " [0 0 0 0 5 0 1 0 0 0]\n",
            " [0 0 0 0 0 4 0 0 0 3]\n",
            " [0 0 0 0 0 0 0 4 2 0]\n",
            " [0 0 1 0 2 0 0 0 0 2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "P, Q = mf(ratings, k=3)\n",
        "\n",
        "print(P)  # User embeddings."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6yvgHkuCwn1V",
        "outputId": "4b7729b9-e442-4cc9-9172-abbb5356df83"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.63030098 1.32632817 0.22731696]\n",
            " [0.91776555 1.65371568 1.13847576]\n",
            " [0.94394792 1.20334036 0.08460967]\n",
            " [1.48581284 1.84234102 0.85833273]\n",
            " [0.90108838 0.48804721 0.31216772]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(Q)  # Item embeddings."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZrDuSoUwqwR",
        "outputId": "01fad903-81e8-4ae9-fa1b-29ad6a03334e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.69258857  0.83594341  0.42432199]\n",
            " [ 0.8487743   0.54679121  0.35410346]\n",
            " [ 0.73827766  0.1010681   0.87686572]\n",
            " [ 0.33625828  0.89183268  0.296849  ]\n",
            " [ 0.87169152  1.62740441  1.29970871]\n",
            " [ 1.50389245  2.12570844  0.65550343]\n",
            " [ 0.37660684  0.52827304 -0.1436639 ]\n",
            " [ 1.11657344  0.99507904  0.50060044]\n",
            " [ 0.32235812  0.39279822  0.93554762]\n",
            " [ 1.48046418  1.27550157  0.17612006]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# User similarity.\n",
        "l2 = np.sqrt(pow(P, 2).sum(axis=1))\n",
        "user_sim = P.dot(P.T) / np.outer(l2, l2)\n",
        "print(np.round(user_sim, 2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2M9QIe_wwGk",
        "outputId": "b726e1fd-9ca5-42c1-c72f-251cdbab7d7b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.   0.92 0.97 0.96 0.81]\n",
            " [0.92 1.   0.87 0.97 0.84]\n",
            " [0.97 0.87 1.   0.96 0.89]\n",
            " [0.96 0.97 0.96 1.   0.93]\n",
            " [0.81 0.84 0.89 0.93 1.  ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Not run.\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "cosine_similarity(P)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgmeWJ3uw0RX",
        "outputId": "f2078b60-8d48-46aa-da95-0bb731fcb34d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.        , 0.9238834 , 0.97105358, 0.95563301, 0.80800464],\n",
              "       [0.9238834 , 1.        , 0.8732077 , 0.96936203, 0.84127185],\n",
              "       [0.97105358, 0.8732077 , 1.        , 0.95740149, 0.89236845],\n",
              "       [0.95563301, 0.96936203, 0.95740149, 1.        , 0.92913622],\n",
              "       [0.80800464, 0.84127185, 0.89236845, 0.92913622, 1.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = P.dot(Q.T)\n",
        "mask = np.zeros_like(ratings)\n",
        "mask[ratings.nonzero()] = 1\n",
        "\n",
        "# Mask out unknown ratings as 0 for ease of comparison.\n",
        "print(np.round(predictions * mask, 2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UvKUN7_Ow3se",
        "outputId": "84c15fc7-d12c-4db4-91a2-d7bfb81f0757"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.   0.   0.   0.   3.   3.92 0.91 2.14 0.   0.  ]\n",
            " [0.   0.   0.   0.   4.97 0.   1.06 0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   4.03 0.   0.   0.   2.95]\n",
            " [0.   0.   0.   0.   0.   0.   0.   3.92 2.01 0.  ]\n",
            " [0.   0.   0.99 0.   1.99 0.   0.   0.   0.   2.01]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mask out known ratings as 0 for ease of comparison.\n",
        "print(np.round(predictions * (1 - mask), 2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQyaRnh2w7ha",
        "outputId": "12aa8696-b3cd-446b-e293-e07b113b1ab5"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.64 1.34 0.8  1.46 0.   0.   0.   0.   0.94 2.66]\n",
            " [2.5  2.09 1.84 2.12 0.   5.64 0.   3.24 2.01 3.67]\n",
            " [1.7  1.49 0.89 1.42 2.89 0.   0.98 2.29 0.86 0.  ]\n",
            " [2.93 2.57 2.04 2.4  5.41 6.71 1.41 0.   0.   4.7 ]\n",
            " [1.16 1.14 0.   0.83 0.   2.6  0.55 1.65 0.77 0.  ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FnEmQ_CjQMHc",
        "outputId": "bbdf4e94-7db8-4919-b11d-d2ebe5ba1036"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.12.0\n"
          ]
        }
      ],
      "source": [
        "import logging\n",
        "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
        "\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MatrixFactorization:\n",
        "  def __init__(self, R, k, lr=.0003, l2=.04, seed=777):\n",
        "    self.R = tf.convert_to_tensor(R, dtype=tf.float32)\n",
        "    self.mask = tf.not_equal(self.R, 0)\n",
        "    self.m, self.n = R.shape\n",
        "    self.k = k\n",
        "    self.lr = lr\n",
        "    self.l2 = l2\n",
        "    self.tol = .001\n",
        "    # Initialize trainable weights.\n",
        "    self.weight_init = tf.random_normal_initializer(seed=seed)\n",
        "    self.P = tf.Variable(self.weight_init((self.m, self.k)))\n",
        "    self.Q = tf.Variable(self.weight_init((self.n, self.k)))\n",
        "\n",
        "  def loss(self):\n",
        "    raise NotImplementedError\n",
        "\n",
        "  def grad_update(self):\n",
        "    with tf.GradientTape() as t:\n",
        "      t.watch([self.P, self.Q])\n",
        "      self.current_loss = self.loss()\n",
        "    gP, gQ = t.gradient(self.current_loss, [self.P, self.Q])\n",
        "    self.P.assign_sub(self.lr * gP)\n",
        "    self.Q.assign_sub(self.lr * gQ)\n",
        "\n",
        "  def train(self, n_epoch=5000):\n",
        "    for epoch in range(n_epoch):\n",
        "      self.grad_update()\n",
        "      if self.current_loss < self.tol:\n",
        "        break\n",
        "\n",
        "\n",
        "class RealValueMF(MatrixFactorization):\n",
        "  # The implementation is far from optimized since we don't need the product of entire P'Q.\n",
        "  # We only need scores for non-missing entries.\n",
        "\n",
        "  def loss(self):\n",
        "    \"\"\"Squared error loss.\"\"\"\n",
        "    E = (self.R - tf.matmul(self.P, self.Q, transpose_b=True))**2\n",
        "    l2_norm = tf.reduce_sum(self.P**2) + tf.reduce_sum(self.Q**2)\n",
        "    out = tf.reduce_sum(tf.boolean_mask(E, self.mask)) + self.l2 * l2_norm\n",
        "    return out"
      ],
      "metadata": {
        "id": "ktslE1viteza"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rvmf_model = RealValueMF(ratings, k=3)\n",
        "rvmf_model.train()\n",
        "\n",
        "predictions = tf.matmul(rvmf_model.P, rvmf_model.Q, transpose_b=True).numpy()\n",
        "print(np.round(predictions * mask, 2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31tfiWP7wJ6M",
        "outputId": "3247cdf6-b3d5-441b-b8a0-b9644c312446"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.    0.    0.   -0.    3.12  3.94  0.78  1.97  0.    0.  ]\n",
            " [ 0.    0.    0.   -0.    4.91  0.    1.14  0.    0.    0.  ]\n",
            " [ 0.    0.    0.   -0.    0.    4.    0.    0.   -0.    2.95]\n",
            " [ 0.   -0.    0.    0.    0.    0.    0.    3.97  1.98 -0.  ]\n",
            " [ 0.    0.    0.96 -0.    1.98  0.    0.    0.   -0.    2.01]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make missing more prevail.\n",
        "responses = [-1, 0, 1]\n",
        "p = np.array([1, 5, 1])\n",
        "m = 5\n",
        "n = 10\n",
        "\n",
        "# A binary response matrix.\n",
        "b_ratings = np.random.choice(responses, size=m*n, p=p / p.sum()).reshape((m, n))\n",
        "print(b_ratings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOSkG0RvxUWe",
        "outputId": "3cba1b57-3f27-4098-818e-885deb4fdbbb"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1  1  0  0  0  1  0  0 -1  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0 -1  0  0 -1  0  0  0  0 -1]\n",
            " [ 0  0  0 -1  1 -1  0  0 -1 -1]\n",
            " [ 0  0 -1  0  0  0  0  0  0  0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BinaryMF(MatrixFactorization):\n",
        "  def train(self, n_epoch=5000):\n",
        "    # Cast 1/-1 as binary encoding of 0/1.\n",
        "    self.labels = tf.cast(tf.not_equal(tf.boolean_mask(self.R, self.mask), -1), dtype=tf.float32)\n",
        "    for epoch in range(n_epoch):\n",
        "      self.grad_update()\n",
        "\n",
        "  # The implementation is far from optimized since we don't need the product of entire P'Q.\n",
        "  # We only need scores for non-missing entries.\n",
        "  # The code is hence for educational purpose only.\n",
        "  def loss(self):\n",
        "    \"\"\"Cross entropy loss.\"\"\"\n",
        "    logits = tf.boolean_mask(tf.matmul(self.P, self.Q, transpose_b=True), self.mask)\n",
        "    logloss = tf.nn.sigmoid_cross_entropy_with_logits(labels=self.labels, logits=logits)\n",
        "    mlogloss = tf.reduce_mean(logloss)\n",
        "    l2_norm = tf.reduce_sum(self.P**2) + tf.reduce_sum(self.Q**2)\n",
        "    return mlogloss + self.l2 * l2_norm"
      ],
      "metadata": {
        "id": "ybUklNhkxcCF"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We increase the learning a bit since logloss has a very different scale than squared error.\n",
        "# For the same reason we decrease the L2 coefficient.\n",
        "bmf_model = BinaryMF(b_ratings, k=3, lr=.03, l2=.0001)\n",
        "bmf_model.train()\n",
        "\n",
        "b_predictions = tf.sigmoid(tf.matmul(bmf_model.P, bmf_model.Q, transpose_b=True)).numpy()\n",
        "\n",
        "b_mask = np.zeros_like(b_ratings)\n",
        "b_mask[b_ratings.nonzero()] = 1\n",
        "\n",
        "print(np.round(b_predictions * b_mask, 2)) # Prediction on training entries."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Av618lbnxjg8",
        "outputId": "4b3dcff6-1f35-4ce4-bfd5-439d049f0793"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.99 1.   0.   0.   0.   0.99 0.   0.   0.01 0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.01 0.   0.   0.01 0.   0.   0.   0.   0.02]\n",
            " [0.   0.   0.   0.01 0.99 0.01 0.   0.   0.01 0.01]\n",
            " [0.   0.   0.04 0.   0.   0.   0.   0.   0.   0.  ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.round(b_predictions, 2))  # Prediction for all entries."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWw3PTs8xzWm",
        "outputId": "e1d0eab4-a975-40df-ad77-d33294958861"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.99 1.   0.07 0.23 0.99 0.99 0.51 0.49 0.01 0.99]\n",
            " [0.52 0.52 0.52 0.51 0.5  0.54 0.5  0.5  0.5  0.53]\n",
            " [0.02 0.01 0.94 0.73 0.01 0.02 0.5  0.52 0.98 0.02]\n",
            " [0.73 0.8  0.01 0.01 0.99 0.01 0.5  0.54 0.01 0.01]\n",
            " [0.83 0.9  0.04 0.09 0.97 0.29 0.49 0.51 0.04 0.37]]\n"
          ]
        }
      ]
    }
  ]
}